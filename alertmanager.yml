# Alertmanager Configuration for HIVE-R
#
# Routing:
#   critical â†’ PagerDuty / Opsgenie (pages on-call)
#   warning  â†’ Slack channel #hive-alerts
#   info     â†’ Log only (null receiver)
#
# Anti-spam: 5-minute group_wait, 10-minute group_interval, 4-hour repeat

global:
  resolve_timeout: 5m
  # Uncomment and set for Slack:
  # slack_api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'

# ============================================================================
# TEMPLATES
# ============================================================================
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# ============================================================================
# ROUTING TREE
# ============================================================================
route:
  # Group alerts by name to prevent storm (e.g., all HighErrorRate go together)
  group_by: ['alertname', 'severity']

  # Wait 5 min to batch initial alerts in a group
  group_wait: 5m

  # Wait 10 min before sending updates for a group
  group_interval: 10m

  # Don't repeat the same alert within 4 hours
  repeat_interval: 4h

  # Default route: Slack warnings
  receiver: 'slack-warnings'

  routes:
    # Critical alerts â†’ page on-call
    - match:
        severity: critical
      receiver: 'pagerduty-critical'
      group_wait: 30s        # Page quickly for critical
      repeat_interval: 1h    # Re-page hourly if unresolved
      continue: true         # Also send to Slack

    # Critical also goes to Slack for visibility
    - match:
        severity: critical
      receiver: 'slack-critical'

    # Warning â†’ Slack channel
    - match:
        severity: warning
      receiver: 'slack-warnings'

    # Info â†’ silent (log only, no notification)
    - match:
        severity: info
      receiver: 'null'

# ============================================================================
# INHIBITION RULES
# ============================================================================
# Prevent noisy downstream alerts when root cause is known
inhibit_rules:
  # If circuit breaker is open (critical), suppress the latency warning
  # since high latency is a symptom of the circuit being open
  - source_match:
      alertname: CircuitBreakerOpen
    target_match:
      alertname: HighLatency
    equal: []

  # If error rate is critical, suppress half-open info
  - source_match:
      alertname: HighErrorRate
    target_match:
      alertname: CircuitBreakerHalfOpen
    equal: []

# ============================================================================
# RECEIVERS
# ============================================================================
receivers:
  # â”€â”€ Silent (info) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - name: 'null'

  # â”€â”€ PagerDuty (critical) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Replace with your PagerDuty integration key
  - name: 'pagerduty-critical'
    # Uncomment and configure:
    # pagerduty_configs:
    #   - service_key: 'YOUR_PAGERDUTY_INTEGRATION_KEY'
    #     description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
    #     severity: 'critical'
    #     details:
    #       runbook: '{{ .CommonAnnotations.runbook_url }}'
    #       dashboard: '{{ .CommonAnnotations.dashboard_url }}'
    #       firing: '{{ .Alerts.Firing | len }}'
    #       resolved: '{{ .Alerts.Resolved | len }}'
    webhook_configs:
      - url: 'http://localhost:9999/pagerduty-placeholder'
        send_resolved: true

  # â”€â”€ Slack Critical â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - name: 'slack-critical'
    slack_configs:
      - channel: '#hive-alerts-critical'
        send_resolved: true
        title: 'ðŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'
        text: >-
          *Summary*: {{ .CommonAnnotations.summary }}

          *Description*: {{ .CommonAnnotations.description }}

          *Runbook*: {{ .CommonAnnotations.runbook_url }}

          *Firing*: {{ .Alerts.Firing | len }} | *Resolved*: {{ .Alerts.Resolved | len }}
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'

  # â”€â”€ Slack Warning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  - name: 'slack-warnings'
    slack_configs:
      - channel: '#hive-alerts'
        send_resolved: true
        title: 'âš ï¸ {{ .GroupLabels.alertname }}'
        text: >-
          *Summary*: {{ .CommonAnnotations.summary }}

          *Description*: {{ .CommonAnnotations.description }}

          *Runbook*: {{ .CommonAnnotations.runbook_url }}
        color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'
